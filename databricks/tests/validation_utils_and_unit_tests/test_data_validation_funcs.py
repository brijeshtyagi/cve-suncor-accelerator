# Databricks notebook source
!pip install pyyaml

# COMMAND ----------

import unittest
from pyspark.sql import SparkSession, functions as F
from utilities.data_validation_funcs import unique_record_check, consent_check

# COMMAND ----------

class TestDataValidationFunctions(unittest.TestCase):
  """Test class for the data validation functions module"""
  spark = SparkSession.builder.getOrCreate()
  def test_unique_record_check(self):
    df_to_check = spark.createDataFrame([(1, 'A', 'X'), (1, 'A', 'Y'),
                                        (2, 'B', 'Y'), (2, 'A', 'X'),
                                        (4, 'C', 'Z'), (5, 'B', 'Y')],
                                        ['id', 'col1', 'col2'])
    expectation_details = [{'data_validation_check': 'check_record_unique', 'relevant_columns': ['id','col1']}]

    actual_unique_df = unique_record_check(df_to_check, expectation_details, False)
    actual_nonunique_df = unique_record_check(df_to_check, expectation_details, True)

    expected_unique_df = spark.createDataFrame([(2, 'B', 'Y'), (2, 'A', 'X'),
                                                (4, 'C', 'Z'), (5, 'B', 'Y')],
                                               ['id', 'col1', 'col2'])
    expected_nonunique_df = spark.createDataFrame([(1, 'A', 'X', 2), (1, 'A', 'Y', 2)],
                                                  ['id', 'col1', 'col2', 'unique_record_count'])

    self.assertEqual(sorted(actual_unique_df.collect()), sorted(expected_unique_df.collect()))
    self.assertEqual(sorted(actual_nonunique_df.collect()), sorted(expected_nonunique_df.collect()))
  
  def test_consent_check(self):
    consent_df = (spark.createDataFrame(
      [(1, "2023-05-04 10:30:00", "2023-05-07 12:45:00", "requested"),
       (2, "2023-05-03 10:30:00", None, None),
       (3, "2023-04-09 10:30:00", "2023-04-18 12:45:00", "requested"),
       (4, "2023-05-01 10:30:00", "2024-05-01 12:45:00", "preset")],
      ["id","opt_in_dt","opt_out_dt","opt_out_reason"])
      .withColumn("opt_in_dt", F.to_timestamp("opt_in_dt", "yyyy-MM-dd HH:mm:ss"))
      .withColumn("opt_out_dt", F.to_timestamp("opt_out_dt", "yyyy-MM-dd HH:mm:ss")))
    consent_df.createOrReplaceTempView("consent_table")

    df_to_check = (spark.createDataFrame([
      (1, "a", "a", "2023-05-08 10:30:00"),
      (2, "b", "b", "2023-05-08 10:30:00"),
      (3, "c", "c", "2023-05-08 10:30:00"),
      (4, "c", "c", "2023-05-08 10:30:00"),
      (5, "c", "c", "2023-05-08 10:30:00")],
      ["patient_id","col1","col2","record_date"])
      .withColumn("record_date", F.to_timestamp("record_date", "yyyy-MM-dd HH:mm:ss")))
    
    expected_df = (spark.createDataFrame([
      (1, "a", "a", "2023-05-08 10:30:00", "Invalid"),
      (2, "b", "b", "2023-05-08 10:30:00", "Valid"),
      (3, "c", "c", "2023-05-08 10:30:00", "Invalid"),
      (4, "c", "c", "2023-05-08 10:30:00", "Valid"),
      (5, "c", "c", "2023-05-08 10:30:00", "Invalid")],
      ["patient_id","col1","col2","record_date","consent_check"])
      .withColumn("record_date", F.to_timestamp("record_date", "yyyy-MM-dd HH:mm:ss")))

    actual_df = consent_check("consent_table", df_to_check, "id", "patient_id", "record_date")

    self.assertEqual(actual_df.collect(), expected_df.collect())

suite = unittest.TestLoader().loadTestsFromTestCase(TestDataValidationFunctions)
runner = unittest.TextTestRunner(verbosity=2)
print(runner.run(suite))
