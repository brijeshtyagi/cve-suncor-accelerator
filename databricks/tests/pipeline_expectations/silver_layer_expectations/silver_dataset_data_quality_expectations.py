# Databricks notebook source
 # Ensure that Great Expectations is installed

 %pip install great-expectations

# COMMAND ----------

# Text parameters:
# Parameter to store the name of schema:
dbutils.widgets.text("schema_name","dbx_accelerator_silver")

# Paramter to store the specific column name:
dbutils.widgets.text("test_gender_column_name", "gender")
dbutils.widgets.text("test_id_column_name", "patient_id")



# COMMAND ----------

# Import the spark and great expecation dependencies
import pyspark
import json
from pyspark.sql import SparkSession
from pyspark.sql.functions import col
import great_expectations as ge

# Import the ExtendedSparkDFDataset
from great_expectations.dataset import SparkDFDataset
from great_expectations.dataset import MetaSparkDFDataset


# Import the PandaDataset, MetaDataset if needed as below
from great_expectations.dataset import (
    PandasDataset,
    MetaPandasDataset,
)

class RetrievedSilverDataset(SparkDFDataset):
  # """Class that accepts a spark dataset as its incoming dataframe and performs quality 
  #   tests against the finally loaded dataset in the silver layer.   
  # """
  
    _data_asset_type = "SilverDataset"
    tables_details_dict = {}
    patient_columns = []
    table_name = ""

    # create a static method to query through the given table and return the expected dataset.
    @staticmethod
    def returnDatasetForGivenTable(schema_name, table_name):
        return spark.sql(f"SELECT * FROM {schema_name}.{table_name}")
      
# load data using Python JSON module
with open('../tables.json','r') as f:
    RetrievedSilverDataset.tables_details_dict = json.loads(f.read())
RetrievedSilverDataset.patients_columns = (RetrievedSilverDataset.tables_details_dict['Tables'][0]['Table1Columns'])
RetrievedSilverDataset.table_name = (RetrievedSilverDataset.tables_details_dict['Tables'][0]['Table1'])


# #Verify data quality for expected fields in patients' table
df_dataset = RetrievedSilverDataset.returnDatasetForGivenTable((dbutils.widgets.get("schema_name")), (RetrievedSilverDataset.table_name))
df_silver_table_dataset = SparkDFDataset(df_dataset)                                                             
print(df_silver_table_dataset.expect_column_values_to_be_in_set(dbutils.widgets.get("test_gender_column_name"), value_set=["Male", "Female"]))
print(df_silver_table_dataset.expect_column_values_to_be_unique(dbutils.widgets.get("test_id_column_name")))
for column in RetrievedSilverDataset.patients_columns:
    print(df_silver_table_dataset.expect_column_values_to_not_be_null(column))
