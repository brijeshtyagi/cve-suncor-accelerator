# Databricks notebook source
# Install libraries
%pip install pyyaml
%pip install dlt

# COMMAND ----------

# Append the path to the databricks folder to the system path
import sys
sys.path.append('/Workspace/Shared/databricks/')

# COMMAND ----------

# Import libraries
import dlt
import datetime
import pyspark.sql.functions as F
#from utilities.op_utilities import get_config, get_expectation_and_quarantine_rules, create_quarantine_records, send_records_to_quarantine
#from utilities.data_validation_funcs import unique_record_check, consent_check
from utilities.op_utilities import get_config, get_schema_from_json,get_expectation_and_quarantine_rules, create_quarantine_records, send_records_to_quarantine

# COMMAND ----------

# Get the pipeline parameters
config_file_path = spark.conf.get("config_file_path")
params = get_config(config_file_path)

# Bronze to silver parameters
bronze_to_silver_params = params["silver_ingestion_details"]

bronze_schema = bronze_to_silver_params["source_bronze_schema"]
bronze_table = f"{bronze_schema}.{bronze_to_silver_params['source_bronze_table']}"

# Data validation check details
expectation_details = bronze_to_silver_params["data_check"]["expectations"]
expectation_rules = get_expectation_and_quarantine_rules(expectation_details)[
    "expectation_rules"
]
quarantine_rules = get_expectation_and_quarantine_rules(expectation_details)[
    "quarantine_rules"
]

consent_params = params["consent_process_details"]
check_consent = consent_params["consent_curtbl_needscheck"]
consent_schema = consent_params["consent_reference_database"]
consent_table = f"{consent_schema}.{consent_params['consent_reference_table']}"
consent_table_id = consent_params["consent_tbl_id_col"]
bronze_id = consent_params["consent_curtbl_col_join"]
bronze_record_date = consent_params["consent_curtbl_col_date"]

# Silver/quarantine table details
silver_table = bronze_to_silver_params["silver_table"]
quarantine_schema = bronze_to_silver_params["quarantine_schema"]
quarantine_table = bronze_to_silver_params["quarantine_table"]

# COMMAND ----------

# SILVER LAYER

# Create the silver table with expectation/data validation rules in place
if (expectation_rules != None) and (quarantine_rules != None):

    @dlt.table(name=silver_table)
    @dlt.expect_all_or_drop(expectation_rules)
    def bronze_to_silver():
        raw_df = spark.readStream.format("delta").table(bronze_table)

        if check_consent == "True":
            df_w_consent_check = (
                consent_check(
                    consent_table,
                    raw_df,
                    consent_table_id,
                    bronze_id,
                    bronze_record_date,
                )
                .filter(F.col("consent_check") == "Valid")
                .drop("consent_check")
            )
            final_df = df_w_consent_check.withColumn(
                "silver_last_modified_dt", F.lit(datetime.datetime.now())
            )

        else:
            final_df = raw_df.withColumn(
                "silver_last_modified_dt", F.lit(datetime.datetime.now())
            )
        final_df = final_df.drop("bronze_last_modified_dt")
        return final_df

    @dlt.table(name=quarantine_table, temporary=True)
    def bronze_to_silver_quarantine():
        raw_df = spark.readStream.format("delta").table(bronze_table)

        if check_consent == "True":
            quarantine_df = raw_df.withColumn(
                "is_quarantined", F.expr(quarantine_rules)
            ).filter((F.col("is_quarantined") == True))

            df_w_consent_check = (
                consent_check(
                    consent_table,
                    raw_df,
                    consent_table_id,
                    bronze_id,
                    bronze_record_date,
                )
                .filter(F.col("consent_check") == "Invalid")
                .drop("consent_check")
            )

            final_df = quarantine_df.unionByName(
                df_w_consent_check, allowMissingColumns=True
            )

        else:
            quarantine_df = raw_df.withColumn(
                "is_quarantined", F.expr(quarantine_rules)
            ).filter((F.col("is_quarantined") == True))

            final_df = quarantine_df

        rejected_records = create_quarantine_records(
            final_df, "bronze", "failed data check", silver_table
        )
        send_records_to_quarantine(
            rejected_records, quarantine_schema, quarantine_table, "streaming"
        )

        return rejected_records


# Create the silver table without expectation/data validation rules in place
else:

    if check_consent == "True":

        @dlt.table(name=silver_table)
        def bronze_to_silver():
            raw_df = spark.readStream.format("delta").table(bronze_table)

            df_w_consent_check = (
                consent_check(
                    consent_table,
                    raw_df,
                    consent_table_id,
                    bronze_id,
                    bronze_record_date,
                )
                .filter(F.col("consent_check") == "Valid")
                .drop("consent_check")
            )

            final_df = df_w_consent_check.withColumn(
                "silver_last_modified_dt", F.lit(datetime.datetime.now())
            )
            final_df = final_df.drop("bronze_last_modified_dt")
            return final_df

        @dlt.table(name=quarantine_table, temporary=True)
        def bronze_to_silver_quarantine():
            raw_df = spark.readStream.format("delta").table(bronze_table)

            df_w_consent_check = (
                consent_check(
                    consent_table,
                    raw_df,
                    consent_table_id,
                    bronze_id,
                    bronze_record_date,
                )
                .filter(F.col("consent_check") == "Invalid")
                .drop("consent_check")
            )

            final_df = df_w_consent_check

            rejected_records = create_quarantine_records(
                final_df, "bronze", "failed data check", silver_table
            )
            send_records_to_quarantine(
                rejected_records, quarantine_schema, quarantine_table, "streaming"
            )

            return rejected_records

    # If there are no expectations and no consent check, there is no quarantine table to write (workaround for needing to return DF within DLT table block)
    else:

        @dlt.table(name=silver_table)
        def bronze_to_silver():
            raw_df = spark.readStream.format("delta").table(bronze_table)

            final_df = raw_df.withColumn(
                "silver_last_modified_dt", F.lit(datetime.datetime.now())
            )
            final_df = final_df.drop("bronze_last_modified_dt")
            return final_df
